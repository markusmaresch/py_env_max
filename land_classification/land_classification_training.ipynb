{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2556d992-16d6-4c63-91d5-f33ba0f2859b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://towardsdatascience.com/land-cover-classification-using-tensorflow-in-python-791036eaa373\n",
    "# https://github.com/phelber/EuroSAT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f7e5edb0-2983-4758-8dfe-aec67c7421c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "77b5015d-86c1-452a-8f93-5fb33c2edbf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from PIL import Image\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
    "from tensorflow.python.keras.models import Sequential\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "55fde4a0-9311-4ce2-bfcd-cda2cc536d08",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sns' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [2]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# ===============================================================================\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# plot styles\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[43msns\u001b[49m\u001b[38;5;241m.\u001b[39mset_theme(style\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwhitegrid\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      5\u001b[0m plt\u001b[38;5;241m.\u001b[39mrcParams[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfont.family\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msans-serif\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      6\u001b[0m plt\u001b[38;5;241m.\u001b[39mrcParams[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfont.sans-serif\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mHelvetica\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'sns' is not defined"
     ]
    }
   ],
   "source": [
    "# ===============================================================================\n",
    "# plot styles\n",
    "\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "plt.rcParams['font.family'] = 'sans-serif'\n",
    "plt.rcParams['font.sans-serif'] = 'Helvetica'\n",
    "\n",
    "# ===============================================================================\n",
    "# inspect data\n",
    "\n",
    "train_data_dir = rf'{os.getcwd()}/data/2750'\n",
    "\n",
    "data = {}\n",
    "img_height, img_width = 0, 0\n",
    "for path, dirs, files in os.walk(train_data_dir):\n",
    "    dir_name = path.split('/')[-1]\n",
    "    first_file = files[0]\n",
    "    file_name, file_ext = first_file.split('.')\n",
    "    if file_ext == 'jpg':\n",
    "        image = Image.open(f'{path}/{first_file}')\n",
    "        img_width, img_height = image.size\n",
    "        data[dir_name] = {'count': len(files), 'height': img_height, 'width': img_width}\n",
    "\n",
    "df = pd.DataFrame.from_dict(data, orient='index')\n",
    "print(df.head(10))\n",
    "# ax = df.plot.bar(y='count', rot=45)\n",
    "\n",
    "# ===============================================================================\n",
    "# create training, validation and testing dataset\n",
    "\n",
    "batch_size = 32\n",
    "train_dataset = image_dataset_from_directory(\n",
    "    train_data_dir,\n",
    "    validation_split=0.2,\n",
    "    subset=\"training\",\n",
    "    seed=123,\n",
    "    image_size=(img_height, img_width),\n",
    "    batch_size=batch_size)\n",
    "\n",
    "validation_dataset = image_dataset_from_directory(\n",
    "    train_data_dir,\n",
    "    validation_split=0.2,\n",
    "    subset=\"validation\",\n",
    "    seed=123,\n",
    "    image_size=(img_height, img_width),\n",
    "    batch_size=batch_size)\n",
    "\n",
    "# ===============================================================================\n",
    "# inspect tensorflow training dataset\n",
    "\n",
    "# get class names and number of classes\n",
    "class_names = train_dataset.class_names\n",
    "num_classes = len(class_names)\n",
    "print(f'number of classes: {num_classes}', class_names)\n",
    "\n",
    "# retrieve a single batch of 32 images.\n",
    "image_batch, label_batch = next(iter(train_dataset))\n",
    "\n",
    "# image_batch = tensor of the shape (32, 64, 64, 3), image shape = 64 x 64 x 3 (height x width x channels)\n",
    "# label_batch = tensor of the shape (32,), (integer labels)\n",
    "print(image_batch.shape)\n",
    "print(label_batch.shape)\n",
    "\n",
    "# check image value range\n",
    "first_image = image_batch[0].numpy().astype(\"uint8\")\n",
    "print(np.min(first_image), np.max(first_image))\n",
    "\n",
    "# visualize 10 images from dataset\n",
    "plt.figure()\n",
    "for i in range(10):\n",
    "    ax = plt.subplot(2, 5, i + 1)\n",
    "    image = image_batch[i].numpy().astype(\"uint8\")\n",
    "    plt.imshow(image)\n",
    "    plt.title(class_names[label_batch[i]])\n",
    "    plt.axis(\"off\")\n",
    "plt.show()\n",
    "\n",
    "# ===============================================================================\n",
    "# cache and prefetch for computational efficiency\n",
    "\n",
    "# buffered prefetching yields data from disk without incurring I/O blocking\n",
    "# Dataset.cache keeps the images in memory after they're loaded off disk during the first epoch\n",
    "# Dataset.prefetch overlaps data preprocessing and model execution while training\n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "\n",
    "train_dataset = train_dataset.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)\n",
    "validation_dataset = validation_dataset.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "\n",
    "# ===============================================================================\n",
    "# rescale image values into a range of [0,1]\n",
    "\n",
    "# The RGB channel values are in the [0, 255] range\n",
    "# Standardization rescales data to have a mean of 0 and a standard deviation of 1 (unit variance).\n",
    "\n",
    "rescaling_layer = layers.experimental.preprocessing.Rescaling(\n",
    "    scale=1. / 255,\n",
    "    input_shape=(img_height, img_width, 3)\n",
    ")\n",
    "\n",
    "# rescale data outside of model\n",
    "rescaled_ds = train_dataset.map(lambda x, y: (rescaling_layer(x), y))\n",
    "image_batch, labels_batch = next(iter(rescaled_ds))\n",
    "first_image = image_batch[0].numpy().astype(\"float32\")\n",
    "print(np.min(first_image), np.max(first_image))\n",
    "\n",
    "# ===============================================================================\n",
    "# define data augmentation layer\n",
    "\n",
    "data_augmentation = keras.Sequential([\n",
    "    layers.experimental.preprocessing.RandomFlip(\"horizontal\", input_shape=(img_height, img_width, 3)),\n",
    "    layers.experimental.preprocessing.RandomRotation(0.1),\n",
    "    layers.experimental.preprocessing.RandomZoom(0.1),\n",
    "])\n",
    "\n",
    "# ===============================================================================\n",
    "# build tensorflow sequential convolutional neural network model\n",
    "\n",
    "model = Sequential([\n",
    "\n",
    "    # layer 1 - preprocessing layer with convolution and max pooling\n",
    "    rescaling_layer,\n",
    "    layers.Conv2D(filters=8, kernel_size=3, padding='same',\n",
    "                  activation='relu', input_shape=(img_height, img_width, 3)),\n",
    "    layers.MaxPooling2D(pool_size=(2, 2), strides=None, padding=\"valid\"),\n",
    "\n",
    "    # layer 2 - convolutional layer and max pooling\n",
    "    layers.Conv2D(filters=16, kernel_size=3, padding='same', activation='relu'),\n",
    "    layers.MaxPooling2D(pool_size=(2, 2), strides=None, padding=\"valid\"),\n",
    "\n",
    "    # layer 3 - convolutional layer and max pooling\n",
    "    layers.Conv2D(filters=32, kernel_size=3, padding='same', activation='relu'),\n",
    "    layers.MaxPooling2D(pool_size=(2, 2), strides=None, padding=\"valid\"),\n",
    "\n",
    "    # layer 4 - convolutional layer and max pooling\n",
    "    layers.Conv2D(filters=64, kernel_size=3, padding='same', activation='relu'),\n",
    "    layers.MaxPooling2D(pool_size=(2, 2), strides=None, padding=\"valid\"),\n",
    "    layers.Dropout(rate=0.1),\n",
    "    layers.Flatten(),\n",
    "\n",
    "    # layer 5 - dense fully connected layer\n",
    "    layers.Dense(units=128, activation='relu'),\n",
    "\n",
    "    # layer 6 - output dense layer\n",
    "    layers.Dense(num_classes)\n",
    "])\n",
    "\n",
    "# compile tensorflow sequential CNN model\n",
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# print model summary\n",
    "model.summary()\n",
    "\n",
    "# ===============================================================================\n",
    "# train model\n",
    "\n",
    "epochs = 1\n",
    "history = model.fit(\n",
    "    train_dataset,\n",
    "    validation_data=validation_dataset,\n",
    "    epochs=epochs\n",
    ")\n",
    "model.save(f'{os.getcwd()}/land_cover_model')\n",
    "\n",
    "# ===============================================================================\n",
    "# visualize training metrics\n",
    "\n",
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs_range = range(epochs)\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
    "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs_range, loss, label='Training Loss')\n",
    "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afddd47d-e108-4789-9707-2fda836f6a6b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
